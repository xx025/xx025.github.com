---
permalink: /201107/
excerpt_separator: <!--more-->
---
**实验六 人工神经网络算法实现**
<!--more-->

【实验目的】

1 理解人工神经网络的基本原理。

2 掌握BP算法的原理与编码实现。

3 了解多隐含层神经网络的学习过程。

【实验类型】

设计型

【实验学时】

2学时

【实验环境】

Windows 7以上操作系统

Python3.0以上版本

Pycharm开发环境

Spyder开发环境

【实验要求】

人工神经网络是一种模拟人脑神经结构和工作原理的算法模型，在各工程领域得到了广泛应用。对于多层神经网络，误差逆传播（Error
Back Propagation, BP）算法是一种典型的神经网络学习算法。

（1）请参考下面的参考资料（来自周志华教程），对一个最简单的三层神经网络（一个隐含层）设计学习算法并用python编码实现，自行设计数据进行测试，最后将源代码提交到QQ作业。

（2）请参考给出的资料《前向型神经网络之BPNN(附源码)》，学习了解多隐含层神经网络BP算法的实现，并尝试对源代码进行解读和测试。

``` python
#File BackpropCE.py

import numpy as np

from Sigmoid import *

def BackpropCE(W1, W2, X, D):
    alpha = 0.9
    N = 4
    for k in range(N):
        x = X[k, :].T
        d = D[k]
        v1 = np.matmul(W1, x)
        y1 = Sigmoid(v1)

        v = np.matmul(W2, y1)
        y = Sigmoid(v)

        e = d-y
        delta = e*y*(1-y)

        e1 = np.matmul(W2.T, delta)
        delta1 = y1*(1-y1)*e1

        dW1 = (alpha*delta1).reshape(4, 1)*x.reshape(1, 3)
        W1 = W1+dW1

        dW2 = alpha*delta*y1
        W2 = W2+dW2
    return W1, W2
```

``` python
#File Sigmoid.py
import numpy as np

def Sigmoid(x):
    return 1.0/(1.0+np.exp(-x))

```

``` python
#File TestBackpropCE.py
import numpy as np
from Sigmoid import *
from BackpropCE import *

def TestBackpropCE():
    X = np.array([[0, 0, 0],
                  [0, 1, 1],
                  [1, 0, 1],
                  [1, 1, 1]
                  ])
    D = np.array([[0],
                  [1],
                  [1],
                  [0]
                  ])
    W1 = 2*np.random.random((4, 3))-1
    W2 = 2*np.random.random((1, 4))-1

    for _epoch in range(10000):
        W1, W2 = BackpropCE(W1, W2, X, D)

    N = 4
    for k in range(N):
        x = X[k, :].T
        v1 = np.matmul(W1, x)
        y1 = Sigmoid(v1)
        v = np.matmul(W2, y1)
        y = Sigmoid(v)
        print(y)

if __name__ == "__main__":
    TestBackpropCE()

```
