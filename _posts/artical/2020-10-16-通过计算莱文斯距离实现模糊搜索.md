
- åœ¨ç¼–å†™é—®ç­”å·ç­”é¢˜çš„è¿‡ç¨‹ä¸­æˆ‘å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯ä½ é¢˜åº“é‡Œå­˜çš„é—®é¢˜å’ŒçœŸæ­£å±•ç¤ºçš„é—®é¢˜æœ‰ä¸€äº›ç»†å¾®çš„å·®åˆ«ï¼Œå½“ç„¶å³ä½¿å·®åˆ«ä»…ä»…æ˜¯0.0001ï¼Œå‘åˆ—è¡¨æœç´¢çš„æ—¶å€™ä¾ç„¶ä¼šè¿”å›ç©ºã€‚æˆ‘å°±æƒ³æœ‰æ²¡æœ‰åŠæ³•è§£å†³è¿™ä¸ª`æ¨¡ç³Šæœç´¢`é—®é¢˜ï¼Œå¹¶æ²¡æœ‰èŠ±è´¹å¤šå°‘æ—¶é—´å°±æ‰¾åˆ°äº†ä¸€ä¸ªæ¯”è¾ƒåˆé€‚çš„æ•°å­¦å·¥å…·`èŠæ–‡æ–¯å¦è·é›¢(Levenshteinè·é›¢)`ï¼Œé€šè¿‡è®¡ç®—å­—ç¬¦ä¸²é—´çš„è¿™ä¸ªè·ç¦»å°±èƒ½å¾ˆå®¹æ˜“çš„æ¯”å¯¹å‡ºè¦æœç´¢çš„ç»“æœã€‚

```
ç»´åŸºç™¾ç§‘å‚è€ƒï¼š
èŠæ–‡æ–¯å¦è·é›¢ï¼šhttps://zh.m.wikipedia.org/zh-hk/èŠæ–‡æ–¯å¦è·é›¢
```


```python
# @File    : englishwords.py
lis = ['', 'settle', 'oppose', 'mood', 'craftsman',
            'agitate', 'catholic', 'go-ahe', 'bribery',
            'emphasize']
```

ğŸ‘†è¿™å„¿çš„åˆ—è¡¨åªåˆ—äº†åˆ—è¡¨`lis=..`çš„éƒ¨åˆ†,å®Œæ•´çš„æ–‡ä»¶(ä¸€äº›è‹±è¯­å•è¯)ï¼š
<a  href="https://github.com/xx025/xx025.github.com/blob/master/assets/file/2020-10-16/englishwords.py">englishwords.py</a>  

```python
# @File    : main.py
import Levenshtein
import englishwords

lis = englishwords.lis


def fuzzysearch(str_, lis_):
    lis = [Levenshtein.distance(str_, i) for i in lis_]
    # åˆ†åˆ«è®¡ç®—è±æ–‡æ–¯å¦è·ç¦»ï¼ˆLevenshteinï¼‰
    return lis_[lis.index(min(lis))]
    # è¿”å›åˆ—è¡¨ä¸­è±æ–‡æ–¯è·ç¦»çš„æœ€å°å€¼çš„å­—ç¬¦ä¸²


print(fuzzysearch('directy', lis))
print(fuzzysearch('dieooooooocty', lis))
```
```
è¾“å‡ºï¼š
directly
discomfort
```


é™¤ä¸Šé¢å¤–æˆ‘è¿˜æƒ³åˆ°äº†å…¶ä»–ä¸¤ç‚¹:

1. åœ¨ä½ ç»™å®šå­—ç¬¦ä¸²`str`åä¸€èˆ¬ä½ æƒ³è¦çš„ç»“æœ`r_str`åº”è¯¥æœ‰ä¸€å®šçš„é•¿åº¦é™åˆ¶ï¼Œå¦‚
    ```
    |len(r_str)-len(str)|<len(str)*125%
    ```
2. è®¡ç®—çš„è±æ–‡æ–¯è·ç¦»ä¹Ÿåº”è¯¥å­˜åœ¨ä¸€ä¸ªä¸Šé™,å¦‚
    ```
    Levenshtein.distance(str_, i)<=len(str)*25%
    ```
    
