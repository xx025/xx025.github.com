---
date: 2020-11-29 15:43:53
---

**1. 利用 requests 库和正则表达式抓取猫眼电影 TOP100 的相关内容**

**（1）目标网址如下，共10页。**

**https://maoyan.com/board/4?offset=0**

**\...**

**https://maoyan.com/board/4?offset=90**

**（2）定义get_one_page(url)方法，获取指定网页的源代码。**

**（3）定义parse_one_page(html)方法，解析源代码，获取每条电影信息。**

**（4）定义write_to_file(content)方法，将电影信息写入Excel文件中。**

**（5）定义main(offset)方法，总合所有方法。**

**（6）使用for循环遍历所有网址。**

> 代码来源:https://cuiqingcai.com/5534.html
```python
import json
import re
import time
from urllib.request import *

from requests import RequestException

headers = {
    "Referer": " https://maoyan.com/",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36",
    "Cookie": "__mta=45972251.1606014452900.1606615119379.1606631835419.4; uuid_n_v=v1; uuid=DBD7D8402C6F11EB93BE23BC366A55E54D26C2D4CCE34EC4BDEA3E12C1ED449F; _lxsdk_cuid=175edebc406c8-06d4de9738acbe-c791e37-144000-175edebc407c8; _lxsdk=DBD7D8402C6F11EB93BE23BC366A55E54D26C2D4CCE34EC4BDEA3E12C1ED449F; __mta=45972251.1606014452900.1606615119379.1606615131628.4; _csrf=66c0cedff7570c32010c1afbf2a195e3ffc85f5bca744e9c39afab3861162ed4; _lxsdk_s=17612b846fe-38c-df2-ee0%7C%7C2"
}


def get_one_page(url):
    req = Request(url=url, headers=headers, method='POST')
    try:
        response = urlopen(req)
        if response.getcode() == 200:
            return response.read().decode('utf8')
        return None
    except RequestException:
        return None


def parse_one_page(html):
    pattern = re.compile('<dd>.*?board-index.*?>(\d+)</i>.*?data-src="(.*?)".*?name"><a'
                         + '.*?>(.*?)</a>.*?star">(.*?)</p>.*?releasetime">(.*?)</p>'
                         + '.*?integer">(.*?)</i>.*?fraction">(.*?)</i>.*?</dd>', re.S)
    items = re.findall(pattern, html)
    for item in items:
        yield {
            'index': item[0],
            'image': item[1],
            'title': item[2],
            'actor': item[3].strip()[3:],
            'time': item[4].strip()[5:],
            'score': item[5] + item[6]
        }


def write_to_file(content):
    with open('result.txt', 'a', encoding='utf-8') as f:
        f.write(json.dumps(content, ensure_ascii=False) + '\n')


def main(offset):
    url = 'http://maoyan.com/board/4?offset=' + str(offset)
    html = get_one_page(url)
    for item in parse_one_page(html):
        print(item)
        write_to_file(item)


if __name__ == '__main__':
    for i in range(10):
        main(offset=i * 10)
        time.sleep(1)
```