**实验七 支持向量机分类算法实现**

【实验目的】

1 理解支持向量机的基本数学原理。

2 掌握简单支持向量机优化算法SMO的编码实现。

3 了解核函数的使用方法。

【实验类型】

设计型

【实验学时】

2学时

【实验环境】

Windows 7以上操作系统

Python3.0以上版本

Pycharm开发环境

Spyder开发环境

【实验要求】

支持向量机也是常用的一类分类模型，它通过在两类数据之间寻找一个超平面来分隔不同类的数据。支持向量机最后对应一个二次规划模型（其最优化问题的对偶问题），可以使用通常二次规划求解方法求解，也可以使用Platt在1996年提出的SMO（Sequential
Minimal Optimization），它通过一种启发式的误差修正方法求解。

（1）请参考教程中对于SVM模型的描述了解其数学原理。

（2）请参考《机器学习实战》中第6章的内容（后附），完成简化SMO方法的编程，使用提供的测试数据测试，并将最后源码提交到QQ作业。

（3）能顺利完成简化SMO算法的同学， 可继续学习完整的Platt
SMO算法以及核函数的内容并编码实现。


```python
# 代码来自：SMO算法实现（来自《机器学习》实战）P95,96,97
#注：未对摘抄做正确性校验

from numpy import *
from random import random

# SMO算法中的辅助函数

# 打开文件并对其进行逐行解析

def lodaDataSet(fileName):
    dataMat = []
    lableMat = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr = line.strip().split('\t')
        dataMat.append([float(lineArr[0]), float(lineArr[1])])
    return dataMat, lableMat


# 只要函数值不等于输入值i，函数就会进行随机选择

def selectJrand(i, m):
    j = i
    while j == i:
        j = int(random.uniform(0, m))
    return j


# 调整大于H或小于alpha的值

def clipAlpha(aj, H, L):
    if aj > H:
        aj = H
    if L > aj:
        aj = L
    return aj


# 简化版SMO算法
'''
dataMatIn,数据集
classLabels,类别标签
C,常数C
toler,容错率
maxIter,取消前最大的循环次数
'''


def smoSimple(dataMatIn, classLabels, C, toler, maxIter):
    dataMatrix = mat(dataMatIn)
    labelMat = mat(classLabels).transpose()
    b = 0
    m, n = shape(dataMatrix)
    alphas = mat(zeros((m, 1)))
    iter = 0
    while iter < maxIter:
        alphaPairsChanged = 0
        for i in range(m):
            fXi = float(multiply(alphas, labelMat).T *
                        (dataMatrix * dataMatrix[i, :].T)) + b
            Ei = fXi - float(labelMat[i])
            if ((labelMat[i] * Ei < -toler) and (alphas[i] < C)) or (
                    (labelMat[i] * Ei > toler) and (alphas[i] > 0)):
                j = selectJrand(i, m)
                fXj = float(multiply(alphas, labelMat).T *
                            (dataMatrix * dataMatrix[j, :].T)) + b
                Ej = fXj - float(labelMat(j))
                alphaIold = alphas[i].copy()
                alphaJold = alphas[j].copy()
                if labelMat[i] != labelMat[j]:
                    L = max(0, alphas[j] + alphas[i])
                    H = min(C, C + alphas[j] - alphas[i])
                else:
                    L = max(0, alphas[j] - alphas[i] - C)
                    H = min(C, alphas[j] + alphas[i])
                if L == H:
                    print("L==H")
                eta = 2.0 * dataMatrix[i, :] * dataMatrix[j, L].T - dataMatrix[i, :] * dataMatrix[i, :].T - dataMatrix[j, :] * dataMatrix[j, :]
                if eta >= 0:
                    print("eta>=0")
                alphas[j] -= labelMat[j] * (Ei - Ej) / eta
                alphas = clipAlpha(alphas[j], H, L)
                if abs(alphas[j] - alphaJold) < 0.0001:
                    print("j not moving enough")
                else:
                    continue
                alphas[i] += labelMat[j] * labelMat[j] * (alphaJold - alphas[j])
                b1 = b - Ei - labelMat[i] * (
                        alphas[i] - alphaIold) * dataMatrix[i, :] * dataMatrix[i, :].T - labelMat[j] * (alphas[j] - alphaJold) * dataMatrix[i:, ] * dataMatrix[j, :].T
                b2 = b - Ei - labelMat[i] * (
                        alphas[i] - alphaIold) * dataMatrix[i, :] * dataMatrix[j, :].T - labelMat[j] * (alphas[j] - alphaJold) * dataMatrix[j:, ] * dataMatrix[j, :].T
                if 0 < alphas[j] and C > alphas[i]:
                    b = b1
                else:
                    b = (b1 + b2) / 2.0
                alphaPairsChanged += 1
                print("inter :{} i:{} ,pairs changed {}".format(
                    iter, i, alphaPairsChanged))
                if 0 < alphaPairsChanged == 0:
                    iter += 1
                else:
                    iter = 0
                print("iteration number :{}".format(iter))
                return b, alphas

```